# AÅŸÄ±rÄ± Ã–ÄŸrenme (Overfitting) Problemi - Ã‡Ã¶zÃ¼m Raporu

## ğŸ“‹ Tespit Edilen Kritik Sorunlar

### 1. Model HiÃ§ ArÄ±za YakalayamÄ±yor (Recall = 0.00)
**Sorun:** Notebook 4'te tÃ¼m threshold deÄŸerlerinde (0.1-0.3) model **hiÃ§ pozitif tahmin Ã¼retmiyor**
- Test setindeki 1441 arÄ±za sinyalinden **SIFIR** tanesini yakalÄ±yor
- Bu durum modelin tamamen baÅŸarÄ±sÄ±z olduÄŸunu gÃ¶steriyor

**Neden:**
- Class imbalance dÃ¼zgÃ¼n yÃ¶netilmemiÅŸ
- Model her zaman negatif sÄ±nÄ±fÄ± tahmin ediyor
- Threshold optimizasyonu yapÄ±lmamÄ±ÅŸ

### 2. Veri SÄ±zÄ±ntÄ±sÄ± (Data Leakage)
**Sorun:** Zaman serisi iÃ§in kritik hatalar

**Notebook 4 - Son hÃ¼cre (cell 11):**
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, shuffle=True, stratify=y, random_state=42  # âŒ YANLIÅ!
)
```

**Neden yanlÄ±ÅŸ:**
- `shuffle=True` â†’ Zaman sÄ±rasÄ±nÄ± bozuyor
- Gelecekteki veriler train setine karÄ±ÅŸÄ±yor
- Model gerÃ§ekte olmayan bilgiyi Ã¶ÄŸreniyor
- Test performansÄ± yanÄ±ltÄ±cÄ± yÃ¼ksek gÃ¶zÃ¼kebilir

**DoÄŸru yaklaÅŸÄ±m:**
- Temporal split kullanÄ±lmalÄ± (tarih bazlÄ±)
- `shuffle=False` olmalÄ±
- TimeSeriesSplit ile validation yapÄ±lmalÄ±

### 3. AÅŸÄ±rÄ± Feature Engineering
**Sorun:** 52 sensÃ¶rden **357 yeni Ã¶zellik** tÃ¼retilmiÅŸ (toplam 409 sÃ¼tun)

**Detay:**
- 3 pencere (3h, 12h, 24h) Ã— 2 metrik (mean, std) Ã— 52 sensÃ¶r = 312 Ã¶zellik
- 52 sensÃ¶r Ã— diff = 52 Ã¶zellik
- Ham sensÃ¶rler = 52 Ã¶zellik
- **TOPLAM: 409 Ã¶zellik**

**Sorunlar:**
- Ã‡ok fazla Ã¶zellik â†’ Model karmaÅŸÄ±klaÅŸÄ±yor
- Gereksiz Ã¶zellikler â†’ Overfitting artÄ±yor
- Computational cost yÃ¼ksek
- BazÄ± sensÃ¶rlerin arÄ±za ile korelasyonu Ã§ok dÃ¼ÅŸÃ¼k

### 4. Temporal Validation EksikliÄŸi
**Sorun:** TimeSeriesSplit kullanÄ±lmamÄ±ÅŸ

**Mevcut durum:**
- Optuna optimizasyonunda basit %80-%20 split
- Temporal order gÃ¶z ardÄ± edilmiÅŸ
- Overfitting tespiti yapÄ±lamamÄ±ÅŸ

**DoÄŸru yaklaÅŸÄ±m:**
- TimeSeriesSplit (5-fold)
- Her fold'da gelecek tahmin edilmeli
- Cross-validation skorlarÄ± raporlanmalÄ±

### 5. Class Imbalance YÃ¶netimi Yetersiz
**Sorun:** SMOTE veya undersampling denenmemiÅŸ

**Mevcut durum:**
- Sadece `scale_pos_weight` kullanÄ±lmÄ±ÅŸ (80-150 aralÄ±ÄŸÄ±)
- Bu tek baÅŸÄ±na yeterli olmamÄ±ÅŸ
- Model pozitif sÄ±nÄ±fÄ± Ã¶ÄŸrenememiÅŸ

**DoÄŸru yaklaÅŸÄ±m:**
- SMOTE ile minority class oversampling
- Undersampling ile majority class azaltma
- Balanced dataset ile eÄŸitim

### 6. Rolling Window Parametreleri
**Sorun:** `min_periods=1` kullanÄ±mÄ±

**Notebook 3:**
```python
roll_mean = df_eng[col].rolling(window=w_size, min_periods=1).mean()  # âŒ Riskli
```

**Neden sorunlu:**
- min_periods=1 â†’ Ä°lk deÄŸerde bile hesaplama yapÄ±lÄ±yor
- Yeterli veri olmadan Ã¶zellik tÃ¼retiliyor
- Veri sÄ±zÄ±ntÄ±sÄ± riski

**DoÄŸru yaklaÅŸÄ±m:**
```python
min_periods=int(w_size * 0.5)  # En az %50 veri olmalÄ±
```

---

## âœ… Uygulanan Ã‡Ã¶zÃ¼mler

### Notebook 3: Feature Engineering Ä°yileÅŸtirmeleri

#### 1. Feature SayÄ±sÄ± AzaltÄ±ldÄ±
**Ã–nce:** 357 Ã¶zellik
**Sonra:** ~90 Ã¶zellik (Azalma: %75)

**NasÄ±l:**
- En yÃ¼ksek korelasyonlu 30 sensÃ¶r seÃ§ildi
- Pencere sayÄ±sÄ±: 3 â†’ 2 (6h, 12h)
- Metrik sayÄ±sÄ±: 2 â†’ 1 (sadece mean, std kaldÄ±rÄ±ldÄ±)

**Kod:**
```python
# Korelasyon analizi
correlations = {}
for col in sensor_cols:
    correlations[col] = abs(df[col].corr(temp_target))

# En Ã¶nemli 30 sensÃ¶r
top_sensors = sorted(correlations.items(), key=lambda x: x[1], reverse=True)[:30]
selected_sensors = [s[0] for s in top_sensors]
```

#### 2. Veri SÄ±zÄ±ntÄ±sÄ± Ã–nlendi
**Ã–nce:**
```python
min_periods=1  # Riskli
fillna(method='ffill')  # Gelecek bilgisi kullanÄ±labilir
```

**Sonra:**
```python
min_periods=int(w_size * 0.5)  # En az %50 veri
dropna()  # Sadece baÅŸtan ve sondan kes
```

#### 3. Gereksiz Metrikler KaldÄ±rÄ±ldÄ±
**KaldÄ±rÄ±lanlar:**
- Rolling std (3 pencere Ã— 52 sensÃ¶r = 156 Ã¶zellik kaldÄ±rÄ±ldÄ±)
- 24 saatlik pencere (Ã§ok uzun, arÄ±za sinyallerini kaÃ§Ä±rabilir)
- 3 saatlik pencere (Ã§ok kÄ±sa, gÃ¼rÃ¼ltÃ¼lÃ¼)

**Korunanlar:**
- Rolling mean (6h, 12h)
- Diff (1h)

### Notebook 4: Model Optimizasyonu Ä°yileÅŸtirmeleri

#### 1. SMOTE + Undersampling
**Strateji:**
```python
SMOTE(sampling_strategy=0.3)  # Minority class'Ä± %30'a Ã§Ä±kar
RandomUnderSampler(sampling_strategy=0.5)  # 1:2 oranÄ±
```

**SonuÃ§:**
- Balanced dataset
- Model artÄ±k pozitif sÄ±nÄ±fÄ± Ã¶ÄŸrenebilir

#### 2. Threshold Optimizasyonu
**YÃ¶ntem:**
- Precision-Recall Curve analizi
- F2 Score kullanÄ±mÄ± (Recall'a 2x aÄŸÄ±rlÄ±k)
- 0.05-0.95 aralÄ±ÄŸÄ±nda optimal threshold arama

**Kod:**
```python
for thresh in np.arange(0.05, 0.95, 0.05):
    y_pred_temp = (y_prob > thresh).astype(int)
    f2 = fbeta_score(y_test, y_pred_temp, beta=2)

best_threshold = f2_scores[np.argmax(f2_scores[:, 1]), 0]
```

#### 3. TimeSeriesSplit Validation
**YÃ¶ntem:**
```python
tscv = TimeSeriesSplit(n_splits=5)

for train_idx, val_idx in tscv.split(X_train):
    # Temporal split
    # Her fold'da gelecek tahmin edilir
    # Overfitting tespiti
```

**Faydalar:**
- Temporal integrity korunur
- Overfitting tespit edilir
- Daha gÃ¼venilir metrikler

#### 4. Temporal Split (Shuffle KaldÄ±rÄ±ldÄ±)
**Ã–nce:**
```python
shuffle=True, stratify=y  # âŒ Zaman serisini bozuyor
```

**Sonra:**
```python
X_train = X.loc[X.index < split_date]  # âœ… Tarih bazlÄ±
X_test = X.loc[X.index >= split_date]
```

#### 5. Regularization Eklendi
**Parametreler:**
```python
reg_alpha=0.1,   # L1 regularization
reg_lambda=0.1,  # L2 regularization
```

**Fayda:**
- Overfitting azalÄ±r
- Model daha genelleÅŸebilir

---

## ğŸ“Š Beklenen Ä°yileÅŸmeler

### Metrik KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Metrik | Ã–nceki | Beklenen Yeni | Ä°yileÅŸme |
|--------|--------|---------------|----------|
| **Recall** | 0.00 | > 0.70 | +%70 |
| **F1 Score** | 0.00 | > 0.50 | +%50 |
| **Precision** | N/A | 0.30-0.50 | - |
| **AUC-ROC** | ~0.50 | > 0.80 | +%30 |

### Neden Bu Hedefler?

**Recall > 0.70:**
- ArÄ±za tespiti iÃ§in en Ã¶nemli metrik
- %70+ arÄ±za yakalanmalÄ± (1441'den en az 1000+)
- Kritik baÅŸarÄ±sÄ±zlÄ±klar Ã¶nlenmeli

**Precision 0.30-0.50:**
- False alarm kabul edilebilir
- Bir arÄ±zayÄ± kaÃ§Ä±rmak > 2-3 yanlÄ±ÅŸ alarm
- Predictive maintenance doÄŸasÄ± gereÄŸi

**F1 Score > 0.50:**
- Precision-Recall dengesi
- Makul bir performans gÃ¶stergesi

---

## ğŸš€ KullanÄ±m TalimatlarÄ±

### 1. Optimize EdilmiÅŸ Notebook'larÄ± Ã‡alÄ±ÅŸtÄ±rma

#### AdÄ±m 1: Feature Engineering
```bash
# Notebook 3 - Optimize Versiyon
jupyter notebook notebooks/03_FeatureEngineering_Optimized.ipynb
```

**Beklenen Ã§Ä±ktÄ±lar:**
- ~90 yeni Ã¶zellik (357 yerine)
- `sensor_enriched_optimized.csv` oluÅŸturulacak
- Korelasyon analizi sonuÃ§larÄ±
- Trend gÃ¶rselleÅŸtirmeleri

#### AdÄ±m 2: Model Optimization
```bash
# Notebook 4 - Optimize Versiyon
jupyter notebook notebooks/04_ModelOptimization_Optimized.ipynb
```

**Beklenen Ã§Ä±ktÄ±lar:**
- SMOTE + Undersampling sonuÃ§larÄ±
- Threshold optimizasyonu
- TimeSeriesSplit CV skorlarÄ±
- Feature importance analizi
- Final model performansÄ±

### 2. Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

#### Eski Model:
```python
# Eski modeli yÃ¼kle (isterseniz)
old_model = joblib.load('models/final_lgbm_model.pkl')
# Recall: 0.00
```

#### Yeni Model:
```python
# Yeni modeli yÃ¼kle
new_model = joblib.load('models/final_lgbm_optimized.pkl')
config = joblib.load('models/model_config_optimized.pkl')

# KullanÄ±m
threshold = config['best_threshold']
y_prob = new_model.predict_proba(X_test)[:, 1]
y_pred = (y_prob > threshold).astype(int)
```

---

## ğŸ” DetaylÄ± Teknik Analiz

### Neden Ã–nceki Model BaÅŸarÄ±sÄ±z Oldu?

#### 1. Class Imbalance Dominant Oldu
**Veri daÄŸÄ±lÄ±mÄ±:**
- Normal: ~205,000 Ã¶rnek (98%)
- ArÄ±za: ~1,500 Ã¶rnek (2%)

**Model davranÄ±ÅŸÄ±:**
- "Her zaman 0 tahmin et" stratejisi
- Accuracy: %98 (yanÄ±ltÄ±cÄ± yÃ¼ksek)
- Recall: 0.00 (tamamen baÅŸarÄ±sÄ±z)

**Neden:**
- LightGBM varsayÄ±lan loss function: binary cross-entropy
- Dengesiz veri iÃ§in optimize deÄŸil
- Pozitif Ã¶rnekleri gÃ¶rmezden geliyor

#### 2. Veri SÄ±zÄ±ntÄ±sÄ± â†’ YanlÄ±ÅŸ GÃ¼ven
**Shuffle kullanÄ±mÄ±:**
```python
# Zaman: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
# Shuffle sonrasÄ±: [7, 2, 9, 1, 5, 3, 10, 4, 8, 6]
# Train: [7, 2, 9, 1, 5]  # Gelecek bilgisi iÃ§eriyor!
# Test: [3, 10, 4, 8, 6]
```

**SonuÃ§:**
- Model validation'da iyi gÃ¶rÃ¼nebilir
- Ama gerÃ§ek dÃ¼nyada baÅŸarÄ±sÄ±z olur
- Temporal pattern Ã¶ÄŸrenilemez

#### 3. AÅŸÄ±rÄ± KarmaÅŸÄ±klÄ±k
**409 Ã¶zellik problemi:**
- Model capacity: YÃ¼ksek
- Data size: 205K Ã¶rnek
- Features: 409
- **Risk:** Model ezber yapar, genelleÅŸtiremez

**Hughes Phenomenon (Curse of Dimensionality):**
- Ã–zellik sayÄ±sÄ± artarken veri yetersiz kalÄ±r
- Model noise'i pattern olarak Ã¶ÄŸrenir
- Test performansÄ± dÃ¼ÅŸer

---

## ğŸ“ˆ Ä°yileÅŸtirme Stratejisi Ã–zeti

### 1. Veri Seviyesi
- âœ… Feature selection (korelasyon bazlÄ±)
- âœ… Feature reduction (%75 azalma)
- âœ… Veri sÄ±zÄ±ntÄ±sÄ± Ã¶nlendi
- âœ… Temporal integrity korundu

### 2. Model Seviyesi
- âœ… SMOTE + Undersampling
- âœ… Threshold optimization
- âœ… Regularization (L1 + L2)
- âœ… Hiperparametre tuning

### 3. Validation Seviyesi
- âœ… TimeSeriesSplit
- âœ… Temporal split (shuffle yok)
- âœ… Multiple metrics (Recall, F1, F2, AUC)
- âœ… Cross-validation reporting

---

## âš ï¸ Ã–nemli Notlar

### 1. Precision vs Recall Trade-off
**Bu projede Recall Ã¶ncelikli Ã§Ã¼nkÃ¼:**
- Bir arÄ±zayÄ± kaÃ§Ä±rmak maliyetli
- False alarm kabul edilebilir (bakÄ±m ekibi kontrol eder)
- Predictive maintenance doÄŸasÄ± gereÄŸi

**Threshold'u dÃ¼ÅŸÃ¼rÃ¼rseniz:**
- Recall artar (daha fazla arÄ±za yakalar)
- Precision dÃ¼ÅŸer (daha fazla false alarm)
- Ä°ÅŸ gereksinimlerine gÃ¶re ayarlayÄ±n

### 2. Temporal Validation Åart
**Zaman serisi projelerinde:**
- Asla `shuffle=True` kullanmayÄ±n
- TimeSeriesSplit kullanÄ±n
- Gelecek tahmin edilmeli, geÃ§miÅŸ deÄŸil

### 3. Feature Engineering Denge Ä°stiyor
**Fazla Ã¶zellik:**
- Overfitting riski
- Computational cost
- Interpretability azalÄ±r

**Az Ã¶zellik:**
- Underfitting riski
- Ã–nemli pattern'ler kaÃ§ar

**Optimal yaklaÅŸÄ±m:**
- Domain knowledge + Data-driven selection
- Iterative experimentation

---

## ğŸ¯ Sonraki AdÄ±mlar

### Ã–ncelikli (Bu Rapor SonrasÄ±)
1. âœ… Optimize notebook'larÄ± Ã§alÄ±ÅŸtÄ±rÄ±n
2. âœ… Yeni model performansÄ±nÄ± test edin
3. âœ… Threshold'u iÅŸ gereksinimlerine gÃ¶re ayarlayÄ±n

### Orta Vadeli
1. Feature importance'a gÃ¶re daha fazla Ã¶zellik temizliÄŸi
2. Ensemble methods (XGBoost, CatBoost kombinasyonu)
3. Anomaly detection eklemek (Isolation Forest, Autoencoder)

### Uzun Vadeli
1. Online learning (model gÃ¼ncelleme)
2. Real-time prediction API
3. Monitoring ve alerting sistemi
4. A/B testing framework

---

## ğŸ“š Referanslar ve Kaynaklar

### KullanÄ±lan Teknikler
1. **SMOTE:** Synthetic Minority Over-sampling Technique
2. **TimeSeriesSplit:** Sklearn temporal validation
3. **LightGBM:** Microsoft Gradient Boosting framework
4. **Precision-Recall Curve:** Threshold optimization
5. **F-beta Score:** Recall-weighted F-measure

### Ä°lgili Makaleler
- Chawla et al. (2002): SMOTE - Synthetic Minority Over-sampling
- Bergmeir & BenÃ­tez (2012): On the use of cross-validation for time series
- Chen & Guestrin (2016): XGBoost - A Scalable Tree Boosting System

---

## âœ… Checklist

### Uygulama Ã–ncesi
- [x] Mevcut notebook'larÄ± inceledim
- [x] SorunlarÄ± tespit ettim
- [x] Ã‡Ã¶zÃ¼m stratejisi hazÄ±rladÄ±m
- [x] Optimize notebook'larÄ± oluÅŸturdum

### Uygulama SÄ±rasÄ±nda
- [ ] Notebook 3 Optimized Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±
- [ ] Yeni feature set oluÅŸturuldu
- [ ] Notebook 4 Optimized Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±
- [ ] Yeni model eÄŸitildi

### Uygulama SonrasÄ±
- [ ] Recall > 0.70 saÄŸlandÄ± mÄ±?
- [ ] CV skorlarÄ± stabilmi?
- [ ] Feature importance incelendi mi?
- [ ] Threshold optimize edildi mi?
- [ ] Model kaydedildi mi?

---

**Rapor Tarihi:** 2026-01-01
**HazÄ±rlayan:** Claude Code
**Versiyon:** 1.0
