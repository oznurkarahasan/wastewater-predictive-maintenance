"""
HÄ±zlÄ± Test - Model ve Threshold Optimizasyonu
==============================================
Bu script optimize edilmiÅŸ modeli hÄ±zlÄ±ca test eder
"""

import os
import sys

print("="*70)
print("ğŸ§ª HIZLI TEST - Threshold Optimization Validasyonu")
print("="*70)

# Gerekli kÃ¼tÃ¼phaneleri kontrol et
try:
    import pandas as pd
    import numpy as np
    import lightgbm as lgb
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import classification_report, f1_score
    from imblearn.over_sampling import SMOTE
    print("âœ… TÃ¼m kÃ¼tÃ¼phaneler yÃ¼klÃ¼")
except ImportError as e:
    print(f"âŒ Eksik kÃ¼tÃ¼phane: {e}")
    print("\nGerekli kÃ¼tÃ¼phaneler:")
    print("  pip install pandas numpy scikit-learn lightgbm imbalanced-learn matplotlib seaborn")
    sys.exit(1)

# Veri yolu kontrolÃ¼
data_paths = [
    '/home/user/wastewater-predictive-maintenance/data/processed/sensor_enriched.csv',
    'data/processed/sensor_enriched.csv',
    '../data/processed/sensor_enriched.csv',
    'd:/wastewater-predictive-maintenance/data/processed/sensor_enriched.csv'
]

data_path = None
for path in data_paths:
    if os.path.exists(path):
        data_path = path
        break

if data_path is None:
    print("\nâš ï¸ UYARI: sensor_enriched.csv bulunamadÄ±!")
    print("\nVeri dosyasÄ± yollarÄ± kontrol edildi:")
    for path in data_paths:
        print(f"  âŒ {path}")
    print("\nÃ‡Ã¶zÃ¼m:")
    print("  1. Veri dosyasÄ±nÄ± uygun bir yere kopyalayÄ±n")
    print("  2. Veya script iÃ§indeki data_paths listesine doÄŸru yolu ekleyin")
    sys.exit(1)

print(f"âœ… Veri bulundu: {data_path}")

# HÄ±zlÄ± veri analizi
print("\n" + "="*70)
print("ğŸ“Š VERÄ° ANALÄ°ZÄ°")
print("="*70)

df = pd.read_csv(data_path, parse_dates=['timestamp'], index_col='timestamp')
X = df.drop(columns=['y', 'machine_status'], errors='ignore')
drop_cols = [c for c in X.columns if 'sensor_40' in c]
X = X.drop(columns=drop_cols)
y = df['y']

print(f"Toplam Ã–rnek: {len(y):,}")
print(f"Class 0: {(y==0).sum():,} ({(y==0).sum()/len(y)*100:.2f}%)")
print(f"Class 1: {(y==1).sum():,} ({(y==1).sum()/len(y)*100:.2f}%)")
print(f"Ä°mbalance Ratio: {(y==0).sum() / (y==1).sum():.1f}:1")

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, shuffle=True, stratify=y, random_state=42
)

print("\n" + "="*70)
print("ğŸ”¬ HIZLI TEST 1: Class Weight Optimization")
print("="*70)

# Basit class weight testi
model = lgb.LGBMClassifier(
    n_estimators=100,
    learning_rate=0.05,
    num_leaves=31,
    scale_pos_weight=50,  # YÃ¼ksek weight
    objective='binary',
    n_jobs=-1,
    verbose=-1,
    random_state=42
)

print("Model eÄŸitiliyor...")
model.fit(X_train, y_train)

# FarklÄ± threshold'larda test
y_proba = model.predict_proba(X_test)[:, 1]

print(f"\nOlasÄ±lÄ±k Ä°statistikleri:")
print(f"  Min:  {y_proba.min():.6f}")
print(f"  Max:  {y_proba.max():.6f}")
print(f"  Mean: {y_proba.mean():.6f}")
print(f"  Std:  {y_proba.std():.6f}")

print("\nThreshold Testi:")
print(f"{'Threshold':>10s} {'Tahmin':>10s} {'Precision':>12s} {'Recall':>10s} {'F1':>10s}")
print("-" * 60)

from sklearn.metrics import precision_score, recall_score, f1_score

best_f1 = 0
best_threshold = 0.05

for th in [0.01, 0.02, 0.03, 0.04, 0.05, 0.07, 0.1]:
    y_pred = (y_proba >= th).astype(int)
    pred_count = y_pred.sum()

    if pred_count > 0:
        prec = precision_score(y_test, y_pred, zero_division=0)
        rec = recall_score(y_test, y_pred, zero_division=0)
        f1 = f1_score(y_test, y_pred, zero_division=0)

        marker = ""
        if f1 > best_f1:
            best_f1 = f1
            best_threshold = th
            marker = " ğŸ¯"

        print(f"{th:10.3f} {pred_count:10d} {prec:12.3f} {rec:10.3f} {f1:10.3f}{marker}")
    else:
        print(f"{th:10.3f} {'0':>10s} {'N/A':>12s} {'N/A':>10s} {'N/A':>10s}")

print(f"\nğŸ† En Ä°yi Threshold: {best_threshold:.3f} (F1={best_f1:.3f})")

# En iyi threshold ile detaylÄ± rapor
y_pred_best = (y_proba >= best_threshold).astype(int)

print("\n" + "="*70)
print(f"ğŸ“Š DETAYLI PERFORMANS RAPORU (Threshold={best_threshold:.3f})")
print("="*70)
print(classification_report(y_test, y_pred_best))

# Confusion matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred_best)
print("\nConfusion Matrix:")
print(f"                 Predicted")
print(f"              0           1")
print(f"Actual 0   {cm[0,0]:6d}    {cm[0,1]:6d}")
print(f"       1   {cm[1,0]:6d}    {cm[1,1]:6d}")

tn, fp, fn, tp = cm.ravel()
print(f"\nDetaylÄ± Metrikler:")
print(f"  True Positives:  {tp:4d} (DoÄŸru tespit edilen arÄ±zalar)")
print(f"  False Positives: {fp:4d} (YanlÄ±ÅŸ alarm)")
print(f"  True Negatives:  {tn:4d} (DoÄŸru normal)")
print(f"  False Negatives: {fn:4d} (KaÃ§Ä±rÄ±lan arÄ±zalar)")

sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
specificity = tn / (tn + fp) if (tn + fp) > 0 else 0

print(f"\n  Sensitivity (Recall): {sensitivity:.3f}")
print(f"  Specificity:          {specificity:.3f}")

# SMOTE testi
print("\n" + "="*70)
print("ğŸ§¬ HIZLI TEST 2: SMOTE")
print("="*70)

try:
    print("SMOTE uygulanÄ±yor...")
    k_neighbors = min(5, y_train.sum() - 1)
    smote = SMOTE(random_state=42, k_neighbors=k_neighbors)
    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

    print(f"SMOTE Ã–ncesi: Class 0={y_train.value_counts()[0]}, Class 1={y_train.value_counts()[1]}")
    print(f"SMOTE SonrasÄ±: Class 0={(y_train_smote==0).sum()}, Class 1={(y_train_smote==1).sum()}")

    model_smote = lgb.LGBMClassifier(
        n_estimators=100,
        learning_rate=0.05,
        num_leaves=31,
        objective='binary',
        n_jobs=-1,
        verbose=-1,
        random_state=42
    )

    model_smote.fit(X_train_smote, y_train_smote)
    y_proba_smote = model_smote.predict_proba(X_test)[:, 1]

    # En iyi threshold bul
    from sklearn.metrics import precision_recall_curve
    precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba_smote)
    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)
    best_idx = np.argmax(f1_scores[:-1])
    optimal_threshold_smote = thresholds[best_idx]

    y_pred_smote = (y_proba_smote >= optimal_threshold_smote).astype(int)

    print(f"\nğŸ¯ SMOTE Optimal Threshold: {optimal_threshold_smote:.4f}")
    print(f"   F1 Score: {f1_scores[best_idx]:.3f}")

    print("\nSMOTE Model PerformansÄ±:")
    print(classification_report(y_test, y_pred_smote))

except Exception as e:
    print(f"âŒ SMOTE HatasÄ±: {e}")

# SonuÃ§
print("\n" + "="*70)
print("âœ… TEST TAMAMLANDI")
print("="*70)

print("\nğŸ“ Ã–NERÄ°LER:")

if best_f1 > 0.2:
    print(f"  âœ… Model Ã§alÄ±ÅŸÄ±yor! En iyi threshold: {best_threshold:.3f}")
    print(f"  âœ… F1 Score: {best_f1:.3f}")

    if tp > 0:
        print(f"  âœ… {tp} arÄ±za baÅŸarÄ±yla tespit edildi!")
    if fn > 0:
        print(f"  âš ï¸ {fn} arÄ±za kaÃ§Ä±rÄ±ldÄ± (threshold dÃ¼ÅŸÃ¼rÃ¼lebilir)")
    if fp > 10:
        print(f"  âš ï¸ {fp} false alarm var (threshold yÃ¼kseltilebilir)")

    print("\n  Sonraki AdÄ±m: threshold_optimizer.py scriptini Ã§alÄ±ÅŸtÄ±rÄ±n:")
    print("    python notebooks/threshold_optimizer.py")
else:
    print(f"  âš ï¸ Model performansÄ± dÃ¼ÅŸÃ¼k (F1={best_f1:.3f})")
    print("  ğŸ”§ Ã–neriler:")
    print("     1. Class weight'i artÄ±rÄ±n (50-100 arasÄ±)")
    print("     2. SMOTE kullanÄ±n")
    print("     3. Daha fazla feature engineering yapÄ±n")
    print("     4. threshold_optimizer.py ile detaylÄ± optimizasyon yapÄ±n")

print("\n" + "="*70)
