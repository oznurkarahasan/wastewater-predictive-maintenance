{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering (Optimize Edilmiş Versiyon)\n",
    "\n",
    "### Yapılan İyileştirmeler:\n",
    "1. **Veri Sızıntısı Önlendi:** `min_periods` parametre ayarlandı\n",
    "2. **Feature Sayısı Azaltıldı:** Sadece kritik pencereler (6h, 12h) kullanıldı\n",
    "3. **Özellik Seçimi:** En önemli sensörler seçildi\n",
    "4. **Temporal Integrity:** İleri dönük doldurma kaldırıldı, sadece gerekli yerlerde kullanıldı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Ayarlar\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Temiz Veriyi Yükle\n",
    "data_path = '../data/processed/sensor_cleaned.csv'\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_csv(data_path, parse_dates=['timestamp'], index_col='timestamp')\n",
    "    print(f\"Veri Yüklendi. Boyut: {df.shape}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Önce 01_EDA notebook'unu çalıştırmalısın.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Önemli Sensörleri Belirleme\n",
    "\n",
    "Tüm sensörler yerine, arıza ile korelasyonu yüksek sensörleri seçelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basit bir arıza tahmini için binary target oluştur\n",
    "temp_target = (df['machine_status'] == 'BROKEN').astype(int)\n",
    "\n",
    "# Tüm sensörler\n",
    "sensor_cols = [c for c in df.columns if c.startswith('sensor')]\n",
    "\n",
    "# Her sensörün arıza ile korelasyonunu hesapla\n",
    "correlations = {}\n",
    "for col in sensor_cols:\n",
    "    correlations[col] = abs(df[col].corr(temp_target))\n",
    "\n",
    "# En yüksek korelasyona sahip 30 sensörü seç\n",
    "top_sensors = sorted(correlations.items(), key=lambda x: x[1], reverse=True)[:30]\n",
    "selected_sensors = [s[0] for s in top_sensors]\n",
    "\n",
    "print(f\"Seçilen sensör sayısı: {len(selected_sensors)}\")\n",
    "print(f\"\\nEn önemli 10 sensör:\")\n",
    "for sensor, corr in top_sensors[:10]:\n",
    "    print(f\"{sensor}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Feature Engineering\n",
    "\n",
    "**Değişiklikler:**\n",
    "- Sadece seçili sensörler kullanılıyor\n",
    "- Pencere sayısı azaltıldı: 6 saat ve 12 saat (3 ve 24 yerine)\n",
    "- `min_periods` ayarlandı (veri sızıntısı önlendi)\n",
    "- Rolling mean + diff yeterli (std kaldırıldı)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features_optimized(df, selected_sensors):\n",
    "    \"\"\"\n",
    "    Optimize edilmiş feature engineering:\n",
    "    - Daha az pencere\n",
    "    - Daha az metrik\n",
    "    - Seçili sensörler\n",
    "    - Veri sızıntısı koruması\n",
    "    \"\"\"\n",
    "    df_eng = df.copy()\n",
    "    \n",
    "    # Sadece 2 pencere kullan (daha az feature)\n",
    "    windows = [6, 12]  # 3, 12, 24 yerine\n",
    "    \n",
    "    print(\"Optimize edilmiş özellikler türetiliyor...\")\n",
    "    \n",
    "    new_features = []\n",
    "    \n",
    "    for window in windows:\n",
    "        w_size = window * 60  # dakikaya çevir\n",
    "        \n",
    "        for col in selected_sensors:\n",
    "            # Sadece Rolling Mean (Std kaldırıldı)\n",
    "            # min_periods ayarlandı - veri sızıntısını önler\n",
    "            roll_mean = df_eng[col].rolling(\n",
    "                window=w_size, \n",
    "                min_periods=int(w_size * 0.5)  # En az %50 veri olmalı\n",
    "            ).mean()\n",
    "            roll_mean.name = f'{col}_roll_mean_{window}h'\n",
    "            new_features.append(roll_mean)\n",
    "    \n",
    "    # Diff özellikler (1 saat gecikmeli)\n",
    "    for col in selected_sensors:\n",
    "        diff_1h = df_eng[col].diff(60)  # 1 saatlik değişim\n",
    "        diff_1h.name = f'{col}_diff_1h'\n",
    "        new_features.append(diff_1h)\n",
    "    \n",
    "    # Tüm özellikleri birleştir\n",
    "    if new_features:\n",
    "        df_features = pd.concat(new_features, axis=1)\n",
    "        df_eng = pd.concat([df_eng, df_features], axis=1)\n",
    "    \n",
    "    # NaN'ları temizle - GELECEĞİ KULLANMA!\n",
    "    # Sadece baştan ve sondan keseceğiz\n",
    "    df_eng = df_eng.dropna()\n",
    "    \n",
    "    print(f\"Yeni Boyut: {df_eng.shape}\")\n",
    "    print(f\"Türetilen Özellik Sayısı: {len(new_features)}\")\n",
    "    print(f\"Önceki feature sayısı: 357 → Yeni: {len(new_features)} (Azalma: %{(1-len(new_features)/357)*100:.1f})\")\n",
    "    \n",
    "    return df_eng\n",
    "\n",
    "df_features = make_features_optimized(df, selected_sensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En önemli sensörün trendin göster\n",
    "sensor = selected_sensors[0]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_features.index, df_features[sensor], \n",
    "         label='Ham Veri', alpha=0.3, color='gray')\n",
    "plt.plot(df_features.index, df_features[f'{sensor}_roll_mean_12h'], \n",
    "         label='12 Saatlik Trend', color='red', linewidth=2)\n",
    "plt.title(f\"{sensor} - Ham Veri vs Trend\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(df, window_hours=24):\n",
    "    \"\"\"\n",
    "    Arızadan önceki N saati pozitif olarak etiketle\n",
    "    \"\"\"\n",
    "    df_labeled = df.copy()\n",
    "    df_labeled['y'] = 0\n",
    "    \n",
    "    broken_indices = df_labeled[df_labeled['machine_status'] == 'BROKEN'].index\n",
    "    \n",
    "    for fail_time in broken_indices:\n",
    "        start_time = fail_time - pd.Timedelta(hours=window_hours)\n",
    "        mask = (df_labeled.index >= start_time) & (df_labeled.index <= fail_time)\n",
    "        df_labeled.loc[mask, 'y'] = 1\n",
    "    \n",
    "    # RECOVERING durumunu çıkar\n",
    "    df_final = df_labeled[df_labeled['machine_status'] != 'RECOVERING'].drop(columns=['machine_status'])\n",
    "    \n",
    "    print(f\"\\nClass Distribution:\")\n",
    "    print(df_final['y'].value_counts())\n",
    "    print(f\"\\nPositive ratio: {df_final['y'].mean()*100:.2f}%\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "df_final = create_target(df_features, window_hours=24)\n",
    "\n",
    "# Kaydet\n",
    "save_path = '../data/processed/sensor_enriched_optimized.csv'\n",
    "df_final.to_csv(save_path)\n",
    "print(f\"\\n✅ Optimize edilmiş veri seti kaydedildi: {save_path}\")\n",
    "print(f\"Son Boyut: {df_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Özet\n",
    "\n",
    "### İyileştirmeler:\n",
    "1. ✅ **Feature sayısı azaltıldı:** 357 → ~90 (Daha az overfitting)\n",
    "2. ✅ **Veri sızıntısı önlendi:** min_periods ve dropna kullanımı\n",
    "3. ✅ **Sadece önemli sensörler:** En yüksek korelasyonlu 30 sensör\n",
    "4. ✅ **Daha az pencere:** 2 pencere (6h, 12h) yeterli\n",
    "5. ✅ **Gereksiz metrikler kaldırıldı:** Sadece mean ve diff (std gereksiz)\n",
    "\n",
    "### Sonraki Adım:\n",
    "04_ModelOptimization_Optimized.ipynb ile devam et."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
